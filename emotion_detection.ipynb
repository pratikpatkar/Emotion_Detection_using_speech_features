{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotion_detection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1klhZlqvDtaHzbLw7ZD12uFTG1xz4Kw5A","authorship_tag":"ABX9TyNPn8mKH64toTjuZjuX1wTu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"G95Mp-icWcG7"},"source":["In this project we detect the human emotion by processing the speech signal.\n","---\n","The feature which are analyze are MFCC, MEL and chroma.\n","The data set hich is used is RAVDESS.\n","The accuracy obtained was in between 50-80%"]},{"cell_type":"code","metadata":{"id":"Lw_YPS2Ytnms"},"source":["## author of code Pratik Patkar\n","\n","#importing all the required libraries\n","import numpy as np\n","import librosa #it use for extracting the feature like mfcc, mel, chroma\n","import soundfile #it is use for reading and writting different format of soundfile\n","import glob \n","import os\n","import pickle #use for serializing and deserializing objects\n","from sklearn.model_selection import train_test_split # for splitting training and testing\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import accuracy_score #to measure the accuracy of model\n","import seaborn as sn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aB-gVg8T1Wf"},"source":["#creating the function to extract the feature from the speech data\n","def extract_feature(file_name, mfcc, chroma, mel):\n","     \n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype=\"float32\")\n","        sample_rate = sound_file.samplerate\n","        if chroma:\n","            stft = np.abs(librosa.stft(X))\n","        result = np.array([])\n","        if mfcc:\n","            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result = np.hstack((result, mfccs))\n","        if chroma:\n","            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n","            result = np.hstack((result, chroma))\n","        if mel:\n","            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n","            result = np.hstack((result, mel))\n","       \n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0bJ42dlT1YW"},"source":["# RAVDESS dataset is use for training and testing the data it has data for 8 types of emotion\n","emotion = {\n","    \"01\": \"neutral\",\n","    \"02\": \"calm\",\n","    \"03\": \"happy\",\n","    \"04\": \"sad\",\n","    \"05\": \"angry\",\n","    \"06\": \"fearful\",\n","    \"07\": \"disgust\",\n","    \"08\": \"surprised\"\n","}\n","\n","# we are training and test model for these 4 basic emotions we can use any no. of emotion in these data\n","AVAILABLE_EMOTIONS = {\n","    \"happy\",\n","    \"sad\",\n","    \"angry\" ,\n","    \"fearful\",\n","    \"disgust\" \n","  \n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wprGDQbNScDy"},"source":["#extracting the required data and obtaining the features anf returning the the split test and training data\n","def load_data(test_size=0.2):\n","    X, y = [], []\n","    for file in glob.glob(\"/content/drive/MyDrive/DAP/audio/Actor_*/*.wav\"):\n","    \n","        basename = os.path.basename(file) \n","       \n","        emotion_observed = emotion[basename.split(\"-\")[2]] #get the emotion label\n","\n","        if emotion_observed not in AVAILABLE_EMOTIONS:     #we are allowing only that emotion that we chose earliar\n","            continue\n","       \n","        features = extract_feature(file, mfcc=True, chroma=True, mel=True)  #extract speech features from extract_feature function define earliar\n","      \n","        X.append(features)\n","        y.append(emotion_observed)\n","  \n","    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)#spliting data in test and training"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fxo8T3OtUHD0"},"source":["#load RAVDESS data using 75% for training and 25% for testing purpose\n","X_train, X_test, y_train, y_test = load_data(test_size=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLtvdHGZUd7L"},"source":["print(\"[+] Number of training samples:\", X_train.shape[0]) #number of samples in training data\n","\n","print(\"[+] Number of testing samples:\", X_test.shape[0]) #number of samples in testing data\n","\n","print(\"[+] Number of features:\", X_train.shape[1]) #number of features used"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9XRNaJbLjXgv"},"source":["Using the SVM classifier"]},{"cell_type":"code","metadata":{"id":"H20CdmGrYt3e"},"source":["from sklearn import svm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOcRBlxlaXG-"},"source":["clf = svm.SVC(kernel='linear')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4bNvLRkmaeEO"},"source":["clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Jm3YBF5Mmbe","collapsed":true},"source":["predictions_train = clf.predict(X_train)\n","predictions_test = clf.predict(X_test)\n","\n","print(classification_report(y_train, predictions_train))\n","sn. heatmap(confusion_matrix(y_train,predictions_train), annot=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugqxuGBuNQy-"},"source":["train_score = accuracy_score(predictions_train, y_train)\n","print(\"score on train data: \", train_score)\n","test_score = accuracy_score(predictions_test, y_test)\n","print(\"score on train data: \", test_score)\n","\n","# calculate the accuracy\n","print(\"Accuracy: {:.2f}%\".format(test_score*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4_rs7GnO6M0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iFOpQo3bjfLo"},"source":["Using random forest classifier"]},{"cell_type":"code","metadata":{"id":"5rqvJgHraoS-"},"source":["from sklearn.ensemble import RandomForestClassifier\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZDPp6C5cCXV"},"source":["clf=RandomForestClassifier(n_estimators=200)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lGux1DW5cCra"},"source":["clf.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivTwH5tFPMga"},"source":["predictions_train = clf.predict(X_train)\n","predictions_test = clf.predict(X_test)\n","\n","print(classification_report(y_train, predictions_train))\n","sn. heatmap(confusion_matrix(y_train,predictions_train), annot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2U7IurdccC8K"},"source":["train_score = accuracy_score(predictions_train, y_train)\n","print(\"score on train data: \", train_score)\n","test_score = accuracy_score(predictions_test, y_test)\n","print(\"score on train data: \", test_score)\n","\n","# calculate the accuracy\n","print(\"Accuracy: {:.2f}%\".format(test_score*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WxeljFRLjpLu"},"source":["Using decision tree classifier"]},{"cell_type":"code","metadata":{"id":"kaeTMk-ZuVoA"},"source":["from sklearn.tree import DecisionTreeClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqDo7E3qtLMu"},"source":["clf = DecisionTreeClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FX6p-DpttL2s"},"source":["clf = clf.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIzO8mhetWmA"},"source":["predictions_train = clf.predict(X_train)\n","predictions_test = clf.predict(X_test)\n","\n","print(classification_report(y_train, predictions_train))\n","sn. heatmap(confusion_matrix(y_train,predictions_train), annot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZI8Ly_oknYYH"},"source":["train_score = accuracy_score(predictions_train, y_train)\n","print(\"score on train data: \", train_score)\n","test_score = accuracy_score(predictions_test, y_test)\n","print(\"score on train data: \", test_score)\n","\n","# calculate the accuracy\n","print(\"Accuracy: {:.2f}%\".format(test_score*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-RmkBvJjvcz"},"source":["Using KNN classifier"]},{"cell_type":"code","metadata":{"id":"42Ba5DDJtXBQ"},"source":["from sklearn.neighbors import KNeighborsClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_U97YGpYvEAb"},"source":["knn = KNeighborsClassifier(n_neighbors=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2A7JHnKvEQV"},"source":["knn.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTCEfH99vEcv"},"source":["predictions_train = clf.predict(X_train)\n","predictions_test = clf.predict(X_test)\n","\n","print(classification_report(y_train, predictions_train))\n","sn. heatmap(confusion_matrix(y_train,predictions_train), annot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5Uv4pOBnhzh"},"source":["train_score = accuracy_score(predictions_train, y_train)\n","print(\"score on train data: \", train_score)\n","test_score = accuracy_score(predictions_test, y_test)\n","print(\"score on train data: \", test_score)\n","\n","# calculate the accuracy\n","print(\"Accuracy: {:.2f}%\".format(test_score*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ymi5e5xj_p3"},"source":["Using MLP Neural Network\n","\n"]},{"cell_type":"code","metadata":{"id":"USf5D8gckFso"},"source":["from sklearn.neural_network import MLPClassifier # multi-layer perceptron model classifier use in program"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1pkoJpCUi6l"},"source":["# defining the parameters of the model\n","model_params = {\n","    'alpha': 0.01,\n","    'batch_size': 256,\n","    'epsilon': 1e-08, \n","    'hidden_layer_sizes': (300,), \n","    'learning_rate': 'adaptive', \n","    'max_iter': 500, \n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVJ0eqHdJ8kv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVQiUmrtUxbm"},"source":["# initialize Multi Layer Perceptron classifier\n","\n","model = MLPClassifier(**model_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZvva92lU1i6"},"source":["# training the model\n","print('training the model..........')\n","model.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWWLWFdqU4Zt"},"source":["\n","predictions_train = model.predict(X_train)\n","predictions_test = model.predict(X_test)\n","#error matrix for training data and performance of classifier in training data\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_train,predictions_train))\n","print(classification_report(y_train, predictions_train))\n","sn. heatmap(confusion_matrix(y_train,predictions_train), annot=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38yn3VCxFqeY"},"source":["\n","train_score = accuracy_score(predictions_train, y_train)\n","print(\"score on train data: \", train_score)\n","test_score = accuracy_score(predictions_test, y_test)\n","print(\"score on train data: \", test_score)\n","\n","# calculate the accuracy\n","print(\"Accuracy: {:.2f}%\".format(test_score*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"veDbxLWonjis"},"source":[""],"execution_count":null,"outputs":[]}]}